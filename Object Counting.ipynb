{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sift to find descriptors for every image, and stack all the descriptors\n",
    "2. use the stacked descriptor to train a kmean for clustering\n",
    "3. create a histogram for every image\n",
    "4. train a linear model to predict the number count of treelogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "class ObjectCounting():\n",
    "    def __init__(self,n_cluster):\n",
    "        self.n_cluster = n_cluster\n",
    "        self.mega_histogram=None\n",
    "        self.kmeans_model = KMeans(n_clusters = n_cluster,verbose=1,n_init=1,max_iter=5)\n",
    "        self.kmean_trained = None\n",
    "        self.reg = LinearRegression()\n",
    "    def _get_img(self,folder):   \n",
    "        img_list=[]\n",
    "        img_file_list=[]\n",
    "        for root,_,files in os.walk(folder):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root,file)\n",
    "                img_list.append(cv2.imread(file_path))\n",
    "                img_file_list.append(file.split(\".\")[:-1])\n",
    "        return img_list, len(img_list), img_file_list\n",
    "#     def _img2gray(self,img):\n",
    "#         return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    def _get_desc(self,img):\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        keypoint, descriptor = sift.detectAndCompute(img, None)\n",
    "        return keypoint, descriptor\n",
    "    \n",
    "    def _get_desc_list(self,img_list):\n",
    "        desc_list=[]\n",
    "        for img in img_list:\n",
    "#             gray = self._img2gray(img)\n",
    "            keypoint, descriptor = self._get_desc(img)\n",
    "            desc_list.append(descriptor)\n",
    "        return desc_list\n",
    "    def _get_stacked_Desc(self,desc_list):\n",
    "        desc_vstack = np.array(desc_list[0])\n",
    "        for desc in desc_list[1:]:\n",
    "            desc_vstack = np.vstack((desc_vstack, desc))\n",
    "        return desc_vstack\n",
    "    def _desc_clustering(self,desc_vstack):\n",
    "        self.kmean_trained = self.kmeans_model.fit_predict(desc_vstack)\n",
    "    def _get_desc_histogram(self,n_images,desc_list):\n",
    "        self.mega_histogram = np.array([np.zeros(self.n_cluster) for i in range(n_images)])\n",
    "        jobs = 0\n",
    "        for img in range(n_images):\n",
    "            descs = len(desc_list[img])\n",
    "            for desc in range(descs):\n",
    "                cluster = self.kmean_trained[jobs+desc]\n",
    "                self.mega_histogram[img][cluster] += 1\n",
    "            jobs += descs\n",
    "    def ModelTraining(self,train,answer):\n",
    "        print(\"Loading Training Dataset\")\n",
    "        train,n_images,img_file_list = self._get_img(train)\n",
    "        print(\"Preprocessing Training Dataset\")\n",
    "        desc_list = self._get_desc_list(train)\n",
    "        desc_vstack = self._get_stacked_Desc(desc_list)\n",
    "        print(\"Clustering Descriptors\")\n",
    "        self._desc_clustering(desc_vstack)\n",
    "        print(\"Creating Bag of Words Vocabulary\")\n",
    "        self._get_desc_histogram(n_images,desc_list)\n",
    "        \n",
    "        X = self.mega_histogram\n",
    "        Y = np.zeros(n_images)\n",
    "        for idx,img_file in enumerate(img_file_list):\n",
    "            Y[idx] = answer.set_index('Image Name').loc[img_file,\"Counts\"]\n",
    "        \n",
    "        self.reg.fit(X, Y)\n",
    "        \n",
    "    def predict(self,test):\n",
    "        print(\"Loading Test Dataset\")\n",
    "        test,n_images,img_file_list = self._get_img(test)\n",
    "        print(\"Preprocessing Test Dataset\")\n",
    "        desc_list = self._get_desc_list(test)       \n",
    "        desc_vstack = self._get_stacked_Desc(desc_list)\n",
    "        print(\"Clustering Descriptors\")\n",
    "        test_clusters = self.kmeans_model.predict(desc_vstack)\n",
    "        print(\"Mapping Bag of Words Vocabulary\")\n",
    "        mega_histogram = np.array([np.zeros(self.n_cluster) for i in range(n_images)])\n",
    "        jobs = 0\n",
    "        for img in range(n_images):\n",
    "            descs = len(desc_list[img])\n",
    "            for desc in range(descs):\n",
    "                cluster = test_clusters[jobs+desc]\n",
    "                mega_histogram[img][cluster] += 1\n",
    "            jobs += descs\n",
    "            \n",
    "        X = mega_histogram\n",
    "        predicted_y = self.reg.predict(X)  \n",
    "        return predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=pd.read_excel('C:\\\\Users\\\\jlyu1\\\\Documents\\\\GitHub\\\\Object-Counting\\\\TreeLogs\\\\Image Count.xlsx')\n",
    "train='C:\\\\Users\\\\jlyu1\\\\Documents\\\\GitHub\\\\Object-Counting\\\\TreeLogs\\\\train'\n",
    "test='C:\\\\Users\\\\jlyu1\\\\Documents\\\\GitHub\\\\Object-Counting\\\\TreeLogs\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Dataset\n",
      "Preprocessing Training Dataset\n",
      "Clustering Descriptors\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 32989060000.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 31526498000.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 31149550000.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 30960820000.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 30840285000.0\n",
      "Creating Bag of Words Vocabulary\n"
     ]
    }
   ],
   "source": [
    "ObjectCounting = ObjectCounting(n_cluster=60)\n",
    "ObjectCounting.ModelTraining(train,answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Test Dataset\n",
      "Preprocessing Test Dataset\n",
      "Clustering Descriptors\n",
      "Mapping Bag of Words Vocabulary\n"
     ]
    }
   ],
   "source": [
    "predictions = ObjectCounting.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.23502286, -54.90767389,  46.57556812,  13.09125139])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
